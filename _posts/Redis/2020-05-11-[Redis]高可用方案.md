---
title: "「Redis」Redis高可用方案"
subtitle: ""
layout: post
author: "afsun"
header-style: text

tags:
  - Redis
---
# 高可用方案

# 分布式Redis

## Redis Cluster

服务端分片,类似于(主从+哨兵+多集群)的方式来实现,客户端只需要将集群当做一个redis就可以

[Linux服务搭建](Untitled%20e7daeb1fb0454695998f1661792f5a3f/Linux%20ebadef6e93db45fa8bd1d3d0be80340f.md)

## 客户端分片

在多个服务器上配置Redis集群,然后在客户端上分片用ShardedJedis实现
# ShardedJedis

分片算法:

- 客户端分片,客户端通过一致性的HASH算法去找到对应的redis结点进行操作

![ShardedJedis%20ac516e86a4824ff48e6df9b6fb5e432f/Untitled.png](http://tuchuansun.oss-cn-hangzhou.aliyuncs.com/typora/202005/11/091045-842552.png)

一般来说，基于redis客户端分片通常使用hash(如一致性hash)、取模等算法。很多时候常用的都是采用**一致性hash**算法，一致性hash算法的好处是当redis节点进行增减时只会影响新增或删除节点前后的小部分数据，相对于取模等算法来说，对数据的影响范围较小。如果将redis作为缓存，并且不考虑数据丢失致使缓存穿透造成的影响，在redis节点增减时可以不用考虑部分数据无法命中的问题。如果将redis作为一个nosql的数据库或者缓存穿透影响会比较大，则需要进行数据的迁移，或者使用***预分配***的方式来延迟或规避扩容。

## 预分片

在项目一开始就在一台服务器上启动最大限度的redis服务如32个,在项目后期可能内存会不够用,那就将一台服务器扩成2台,将其中的部分redis分片切到第二台数据库上.

## 源码分析

maven引入

```xml
<dependency>
      <groupId>redis.clients</groupId>
      <artifactId>jedis</artifactId>
      <version>3.0.0</version>
  </dependency>
```

代码:

```java
// 构造函数
public ShardedJedis(List<JedisShardInfo> shards, Hashing algo, Pattern keyTagPattern) {
    this.algo = algo;
    this.tagPattern = tagPattern;
    initialize(shards);
  }
```

- shards 存放redis的信息列表
- algo 分片算法,默认一致性hash.   redis.clients.util.Hashing
- keyTagPattern 指定key的某一部分进行分片

```java
// 初始化算法
private void initialize(List<S> shards) {
    nodes = new TreeMap<Long, S>();
		// 遍历redis列表信息
    for (int i = 0; i != shards.size(); ++i) {
      final S shardInfo = shards.get(i);
      if (shardInfo.getName() == null) 
				for (int n = 0; n < 160 * shardInfo.getWeight(); n++) {
        nodes.put(this.algo.hash("SHARD-" + i + "-NODE-" + n), shardInfo);
	      }
      else 
				for (int n = 0; n < 160 * shardInfo.getWeight(); n++) {
        nodes.put(this.algo.hash(shardInfo.getName() + "*" + n), shardInfo);
	      }
			
      resources.put(shardInfo, shardInfo.createResource());
    }
  }
```

- 遍历redis列表信息,并创建160个(默认)虚拟结点,如果没有设置名称则用默认名称来进行分片,再将redis信息放入node的set中去,如果提升了weight则会创建更多的虚拟结点,并将更多的key打到这些结点对应的redis服务商.
- 将redis信息作为key,jedis对象作为value插入到resources中去

操作:

```java
// 设置键值对进入redis
	@Override
  public String set(final String key, final String value) {
    Jedis j = getShard(key);
    return j.set(key, value);
  }

// 获取对应的jedis实例
	public R getShard(String key) {
    return resources.get(getShardInfo(key));
  }

// 获取构造定义的key策略
	public String getKeyTag(String key) {
    if (tagPattern != null) {
      Matcher m = tagPattern.matcher(key);
      if (m.find()) return m.group(1);
    }
    return key;
  }

// 获取对应的虚拟结点的redisinfo对象
	public S getShardInfo(String key) {
    return getShardInfo(SafeEncoder.encode(getKeyTag(key)));
  }

// 首先通过key或keytag计算出hash值，然后在TreeMap中找到比这个hash值大的第一个虚拟节点（这个过程就是在一致性hash环上顺时针查找的过程），如果这个hash值大于所有虚拟节点对应的hash，则使用第一个虚拟节点
	public S getShardInfo(byte[] key) {
    SortedMap<Long, S> tail = nodes.tailMap(algo.hash(key));
    if (tail.isEmpty()) {
      return nodes.get(nodes.firstKey());
    }
    return tail.get(tail.firstKey());
  }
```

## 总体过程

初始化

- 初始化时传入 redisinfo列表对象 分片算法 分片key策略
- 对redisInfo进行遍历,默认的分160个虚拟节点(每个redis),将redisInfo按照一定的方式取key再一致性hash得到node的节点号,存入Set中
- 将redisInfo作为key,jedis对象作为value存入resources中

操作时

- 对操作的key进行一致性hash,将得到的hash值去获取node中key≥该hash值的结点
- 如果有返回该结点的信息,如果没有则将节点头返回

# 缓存雪崩

- 同一时间缓存大面积失效,导致请求透过缓存直接打到数据库上,数据库负载过重,可能导致宕机

原因:

- redis集群失效
- 缓存失效
- mysql调用量暴增

### 解决方案

- 采用多个缓存的高可用方案,如sentinel模式和cluster模式避免缓存集群大面积崩溃
- 在缓存失效的时间加上一个随机值,保证失效的时间是散列的
- 服务降级
- 缓存数据预热
- 缓存备份:用主缓存和副缓存,副缓存的失效时间比主缓存要长,主缓存更新后副缓存也更新

并发量不是特别多的情况下可能使用,**加锁排队法**

```java
// 实现思路
public object GetProductListNew(String cacheKey) {
    int cacheTime = 30;
    String lockKey = cacheKey;
    String cacheValue = CacheHelper.get(cacheKey);
		// 如果获取redis没有命中就加一个锁,防止多个线程重复查询空值
    if (cacheValue != null) {
        return cacheValue;
    } else {
        synchronized(lockKey) {
            cacheValue = CacheHelper.get(cacheKey);
            if (cacheValue != null) {
                return cacheValue;
            } else {
	            //这里一般是sql查询数据
                cacheValue = GetProductListFromDB(); 
                CacheHelper.Add(cacheKey, cacheValue, cacheTime);
            }
        }
        return cacheValue;
    }
}
```

并发量较大的场景用**标记法**:

```java

public object GetProductListNew(String cacheKey) {
    int cacheTime = 30;
    // 缓存标记
    String cacheSign = cacheKey + "_sign";
		// 状态值
    String sign = CacheHelper.Get(cacheSign);
    //获取缓存值
    String cacheValue = CacheHelper.Get(cacheKey);
    if (sign != null) {
        return cacheValue; //未过期，直接返回
    } else {
        CacheHelper.Add(cacheSign, "1", cacheTime);
        ThreadPool.QueueUserWorkItem((arg) -> {
						// DB查询最新值
            cacheValue = GetProductListFromDB(); 
		        // 更新缓存值
		        CacheHelper.Add(cacheKey, cacheValue, cacheTime * 2);                 
        });
        return cacheValue;
    }
}
```

同时检索这个key对应的缓存信息和这个key对应的缓存状态.

如果该缓存的状态已经失效,那么开个异步线程从数据库中更新缓存状态.

当前线程直接返回旧值

# 缓存穿透

# 缓存穿透

- 多组数据再缓存中未命中,加重数据库的检索负担

### 解决方案

![Untitled%207676901727b4456d9bf5f570810bab52/Untitled.png](http://tuchuansun.oss-cn-hangzhou.aliyuncs.com/typora/202005/11/091154-245116.png)

缓存穿透对应

- 查询到数据库中为空时,将空值信息和key存入redis中指定过期时间(解决多次查询为空值)
- 给查询条件设置一些规则,提前过滤掉

```java
public object GetProductListNew() {
    int cacheTime = 30;
    String cacheKey = "product_list";

    String cacheValue = CacheHelper.Get(cacheKey);
    if (cacheValue != null) {
        return cacheValue;
    }

    cacheValue = CacheHelper.Get(cacheKey);
    if (cacheValue != null) {
        return cacheValue;
    } else {
        //数据库查询不到，为空
        cacheValue = GetProductListFromDB();
        if (cacheValue == null) {
            //如果发现为空，设置个默认值，也缓存起来
            cacheValue = string.Empty;
        }
        CacheHelper.Add(cacheKey, cacheValue, cacheTime);
        return cacheValue;
    }
}
```

以上的做法有个薄弱点，当大量的数据没有命中并存入大量控制到缓存中，再来一波冷用户请求可能会导致数据库的宕机。

应对这种情况使用：

[Copy of 布隆过滤器](Untitled%207676901727b4456d9bf5f570810bab52/Copy%20of%206a6dc233a780430fb7190ca6c877d808.md)

![Untitled%207676901727b4456d9bf5f570810bab52/Untitled%201.png](http://tuchuansun.oss-cn-hangzhou.aliyuncs.com/typora/202005/11/091156-730919.png)

在查询redis中就是通用的布隆过滤器，（可能的数据都放入）每次修改插入的时候都要去add一下波隆

# 缓存预热

- 项目在上线时,将相关的数据库中的信息写到缓存中来,避免用户从数据库中调用.

## 方案

- 编写脚本,上线前在脚本中将数据写到缓存中
- 编写个缓存刷新页面/API 手动刷新一下

# 保证缓存一致性

# 缓存一致性

尝试不一致的原因:

数据库的写入操作和redis修改操作是两个操作,不可能原子化.所以可能尝试数据不一致的问题

保证一致性的方案:

## 先更新数据库后更新redis（不推荐）

不安全,很有可能出现数据不一致

（1）线程A更新了数据库（2）线程B更新了数据库（3）线程B更新了缓存（4）线程A更新了缓存

这样就会导致缓存中的数据不是最新值

如果写入量较大,那么频繁的写入缓存浪费时间

所以不推荐

## 先删除缓存,再更新数据库

如果在删除缓存到更新完数据库这个时间区间有其他线程获取数据,那么就会将旧数据放入缓存中

如果没有过期时间那一直都是脏数据

## 延迟延迟双删

在2上进行改进的操作.

- 先删除缓存
- 操作数据库
- 休眠n秒
- 删除缓存

如果系统构架为主从复制读写分离的话,那么则需要在休眠时间上面再加一点时间保证从机已经将数据复制过来.可以将第二个缓存删除的操作变成异步操作,加大系统的吞吐量

但是如果第二次删除缓存失败,也会导致不一致

## 先更新数据库,在删缓存

这样也有几率会发送数据不一致的情况:

- 缓存过期
- 线程1读出旧值
- 线程2更新数据库
- 线程2删除缓存
- 线程1将旧值放入缓存

产生的条件是,读值到写入缓存的耗时要比更新数据库的耗时要长,理论上可能会产生脏数据但是可能性比较小.

## 异步淘汰缓存

通过读取binlog的方式，异步淘汰缓存，业务代码侵入低

## 删除缓存失败的情况如何处理？

 不管是延迟双删

### 缓存设置过期时间

等缓存的超时时间过期后，就能获取到准确的数据，最坏的情况下是超时时间内为脏数据

### 重试机制

启动一个服务去订阅数据库的binlog文件，针对binlog文件的操作来对缓存进行操作

![Untitled%20fa5abb3a68f945349b9772e373127b74/Untitled.png](http://tuchuansun.oss-cn-hangzhou.aliyuncs.com/typora/202005/11/091241-462013.png)

流程说明：

1）更新数据库数据；

2）数据库会将操作信息写入binlog日志当中；

3）订阅程序提取出所需要的数据以及key；

4）另起一段非业务代码，获得该信息；

5）尝试删除缓存操作，发现删除失败；

6）将这些信息发送至消息队列；

7）重新从消息队列中获得该数据，重试操作。